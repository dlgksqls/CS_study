<h1>가상 메모리</h1>

<h2 style="color: cornflowerblue"> 물리 주소와 논리 주소</h2>
<p>CPU와 프로세스는 메모리의 하드웨어 상 실제 주소인 <strong>물리 주소</strong>가 아니라 <strong>논리 주소</strong>를이용함</p>
<p>논리 주소는 프로세스마다 부여되는 0번지부터 시작되는 주소 쳬걔를 말함</p>

<h3> 메모리 관리 장치 MMU(Memory Management Unit)</h3>
<p>실제로 저장되어 있는 하드웨어상의 메모리와 상호작용하기 위해서는 반드시 논리 주소와 물리 주소간의 변환이 이루어져야함</p>
<p>MMU는 CPU와 메모리 사이에 위치하며, CPU가 이해하는 논리 주소를 메모리가 이해하는 물리 주소로 변환하는 역할을 함</p>

![MMU.png](image%2FMMU.png)

<h2 style="color: cornflowerblue"> 스와핑과 연속 메모리 할당</h2>
<h3>스와핑</h3>
<p>메모리에 적재된 프로세스들 중에는 현재 실행되고 있지 않은 프로세스도 있을 수 있음</p>
<p>입출력 작업을 요구하며 대기 상태가 되었거나 오랫동안 사용되지 않은 프로세스가 이러한 프로세스에 해당됨</p>
<p>이러한 프로세스들을 임시로 <strong>스왑 영역</strong>이라는 보조기억장치의 일부인 영역으로 쫒아내고, 프로세스를 쫒아낸 자리에 생긴 메모리 상의 빈 공간에 다른 프로세스를 적재하여 실행하는 메모리 관리 방식</p>
<p>현재 실행되지 않는 프로세스가 스왑 영역으로 옮겨지는 것을 <strong>스왑 아웃</strong>, 스왑 영역에 있는 프로세스가 다시 메모리로 옮겨오는 것을 <strong>스왑 인</strong>이라고 함</p>

<h3> 연속 메모리 할당과 외부 단편화</h3>
<p>프로세스에 연속적인 메모리 공간을 할당하는 방식을 <strong>연속 메모리 할당</strong>이라고 함</p>
<p>프로세스들이 메모리에 연속적으로 할당되는 환경에서는 프로세스의 실행과 종료를 반복하며 메모리 사이 사이에 빈 공간이 생김</p>
<p>빈 공간들보다 큰 프로세스를 적재하기 어려움 => 메모리 낭비 = <strong>외부 단편화</strong></p>

![외부 단편화.png](image%2F%EC%99%B8%EB%B6%80%20%EB%8B%A8%ED%8E%B8%ED%99%94.png)

<h2 style="color: cornflowerblue"> 페이징을 통한 가상 메모리 관리</h2>
<p>스와핑과 연속 메모리 할당은 2가지 문제를 내포함</p>
<ul>
    <li>적재와 삭제를 반복하며 생기는 외부 단편화</li>
    <li>물리 메모리보다 큰 프로세스를 실행할 수 없다는 문제</li>
</ul>
<p>이를 해결하기 위한 것 => <strong>가상 메모리</strong></p>
<p>실행하고자 하는 프로그램의 일부만 메모리에 적재해, 실제 메모리보다 더 큰 프로세스를 실행할 수 있도록 만드는 메모리 관리 기법</p>
<p>대표적으로 <strong>페이징, 세그멘테이션</strong>이 있음</p>

<h3> 페이징</h3>
<p>프로세스의 논리 주소 공간을 <strong>페이지</strong>라는 일정한 단위로 나누고, 물리 주소 공간을 페이지와 동일한 크기의 <strong>프레임</strong>이라는 일장한 단위로 나눈 뒤 페이지를 프레임에 할당하는 가상 메모리 관리 기법</p>

![페이징.png](image%2F%ED%8E%98%EC%9D%B4%EC%A7%95.png)

<p>페이지라는 일정한 크기로 잘린 프로세스들을 메모리에 불연속적으로 할당할 수 있다면, 연속 메모리 할당처럼 프로세스 바깥에 빈 공간이 생길 수 없음 => 외부 단편화가 발생하지 않음</p>
<p>페이징 시스템에서의 스왑 아웃은 <strong>페이지 아웃</strong></p>
<p>스왑 인은 <strong>페이지 인</strong></p>

<h4> 페이지 테이블</h4>
<p>물리 메모리 내에 페이지가 불연속적으로 배치되어 있다면, CPU 입장에서는 다음으로 실행할 페이지의 위치를 찾기 어려움</p>
<p>이를 해결하기 위해 프로세스의 페이지와 실제로 적재된 프레임을 짝지어주는 정보인 <strong>페이지 테이블</strong>을 활용함</p>
<p>페이지 번호와 실제로 적재된 프레임 번호가 대응되어 있음</p>

![페이지테이블.png](image%2F%ED%8E%98%EC%9D%B4%EC%A7%80%ED%85%8C%EC%9D%B4%EB%B8%94.png)

<p>페이지 테이블을 구성하고 있는 각각의 행들을 <strong>테이블 엔트리</strong>라고 함</p>

![페이지 테이블 상새.png](image%2F%ED%8E%98%EC%9D%B4%EC%A7%80%20%ED%85%8C%EC%9D%B4%EB%B8%94%20%EC%83%81%EC%83%88.png)

<ul>
    <li>유효 비트 : 해당 페이지에 접근이 가능한지 여부를 알려 주는 정보, 현재 페이지가 메모리 아니면 보조기억장치에 적재되어 있는지 알려 주는 비트, 페이지가 메모리에 적재되어있다면 1, 적재되어 있지 않다면 0</li>
    <li>보호 비트 : 페이지 보호 기능을 위해 존재하는 비트, 읽기를 나타내는 r, 쓰기를 나타내는 w, 실행을 나타내는 x의 조합으로 페이지 접근 권한 관리, 100으로 설정돼있으면 r = 1, w, x = 0</li>
    <li>참조 비트 : CPU가 해당 페이지에 접근한 적이 있는지 여부를 나타내는 비트</li>
    <li>수정 비트 (더티 피트) : 해당 페이지에 데이터를 쓴 적이 있는지 알려 주는 비트</li>
</ul>

<p>내부 단편화 발생</p>

<p>모든 프로세스의 페이지 테이블을 메모리에 두는 것은 1. 메모리 접근 횟수가 많아지고, 2. 메모리 용량을 많이 차지하기 때문에 비효율적임</p>
<p>모든 프로세스의 페이지 테이블이 메모리에 적재되어 있을 경우 CPU는 페이지 테이블에 접근하기 위해 한번, 실제 프레임에 접근하기 위해 한번 총 두번 메모리에 접근해야함</p>

<p>1. 이를 해결하기 위해 <strong>TLB</strong>라는 페이지 테이블의 캐시 메모리가 사용됨 TLB는 페이지 테이블의 캐시이므로 참조 지역성의 원리에 근거해 저장함</p>
<p>CPU가 접근하려는 논리 주소의 페이지 번호가 TLB에 있을 경우 => TLB 히트</p>
<p>CPU가 접근하려는 논리 주소의 페이지 번호가 TLB에 없는 경우 => TLB 미스</p>

<p>2. 페이지 테이블의 크기는 작지 않음 그래서 <strong>계층적 페이징</strong>을 사용함</p>
<h3> 세그멘테이션</h3>
<p>프로세스를 일정한 크기의 페이지 단위가 아닌 가변적 크기의 세그먼트 단위로 분할하는 방식</p>
<p>외부 단편화 발생 가능</p>

<h2 style="color: cornflowerblue"> 페이지 교체 알고리즘</h2>
<p><strong>요구 페이징</strong> : 메모리에 프로세스를 적재할 때 처음부터 모든 페이지를 적재하지 않고, 메모리에 필요한(요구되는) 페이지만을 적재하는 기법</p>
<ol>
    <li>CPU가 특정 페이지에 접근하는 명령어를 실행함</li>
    <li>해당 페이지가 현재 메모리에 있을 경우 CPU는 페이지가 적재된 프레임에 접근함</li>
    <li>해당 페이지가 현재 메모리에 없을 경우 페이지 폴트가 발생함</li>
    <li>페이지 폴트가 발생하면 페이지 폴트 처리 루틴을 통해 해당 페이지를 메모리로 적재하고, 유효 비트를 1로 설정함</li>
    <li>1의 과정을 수행함</li>
</ol>
<ol>
    <li><strong>FIFO(First In First Out) 페이지 교체 알고리즘</strong> : 메모리에 가장 먼저 적재된 페이지부터 스왑 아웃하는 페이지 교체 알고리즘, 초기에 적재되어 줄곧 참조되고 있는 페이지를 스왑 아웃 할 우려가 있음, 페이지 폴트 발생 가능성 높음</li>
    <li><strong>최적(Optimal) 페이지 교체 알고리즘</strong> : 앞으로의 사용 빈도가 가장 낮은 페이지를 교체하는 알고리즘, 가장 낮은 페이지 폴트율을 보장하는 알고리즘이나 '앞으로 가장 적게 사용할 페이지'를 미치 예측하기 어렵기 때문에 실제 구현이 어려운 알고리즘</li>
    <li><strong>LRU(Least Recently Used) 페이지 교체 알고리즘</strong> : 가장 적게 사용한 페이지를 교체하는 알고리즘, 보편적으로 사용되는 교체 알고리즘의 원형임, 이를 기반으로 만들어진 다양한 파생 알고리즘이 있음</li>
</ol>

